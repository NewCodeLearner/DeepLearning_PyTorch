{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkLzjN94wnMEco/hb5lO90",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NewCodeLearner/DeepLearning_PyTorch/blob/main/ConvolutionalNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN's are neural networks that are used to classify images.\n",
        "\n",
        "We'll look at the Mnist Dataset and I'll explain a broad overview of how CNN's work.\n",
        "\n",
        "MNIST Dataset comes with 50000 training set and 10000 test images set\n",
        "\n",
        "setosa.io/image for demo of CNN"
      ],
      "metadata": {
        "id": "PVDoj_-gqRLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NEnqdTwY4FFH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bYyIG3F-p8ly"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets,transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert MNIST image file into Tensor of 4-dimensions (# of images, ht,width,color channel)\n",
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "yuqwmRfH4Z2Z"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data Download and save the MNIST data into local directory\n",
        "train_data = datasets.MNIST(root='/cnn_data',train =True,download=True,transform=transform)"
      ],
      "metadata": {
        "id": "5d04cjXR43jN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.MNIST(root='/cnn_data',train=False,download=True,transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g6hZuiF5RIM",
        "outputId": "97fec528-9ccc-44ca-b881-fd92a7f6c27e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /cnn_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 34871609.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/train-images-idx3-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1187057.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/train-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /cnn_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 8322091.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5831199.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cnn_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /cnn_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS4w89tn509F",
        "outputId": "48c5a1ac-f74c-4892-821d-2cd35999061b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /ccn_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HSR_PuI55Y9",
        "outputId": "5ffe556b-72e0-43e4-a377-e9635292a108"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /cnn_data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a small batch size for images\n",
        "train_loader = DataLoader(train_data,batch_size=10,shuffle=True)\n",
        "train_loader = DataLoader(test_data,batch_size=10,shuffle=False)"
      ],
      "metadata": {
        "id": "2tjong6A7F3p"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define our CNN Model\n",
        "#Describe convolutional layer and what its doing ( 2 Convolutional layers)\n",
        "#this is just an exmaple.\n",
        "conv1= nn.Conv2d(1,6,3,1)  #input size 1,output 6(feature maps),kernel size 3x3 ,stride 1 pixel at a time\n",
        "conv2= nn.Conv2d(6,16,3,1) #6 output becomes input here , 16 output feature maps"
      ],
      "metadata": {
        "id": "30tM_ZFL8Jwc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab 1 MNIST image\n",
        "for i,(X_train,y_train) in enumerate(train_data):\n",
        "    break"
      ],
      "metadata": {
        "id": "2A3MITrR8sK2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "#torch.Size([1, 28, 28]) 1 image of 28x28 size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMCdeSp19kzk",
        "outputId": "a57e638a-7ba4-4f53-cfc4-a22794ed7f46"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = X_train.view(1,1,28,28) # 1 batch--1image--28x28 pixels"
      ],
      "metadata": {
        "id": "OhYsSizj-LwE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform our first convolution\n",
        "x=F.relu(conv1(x)) #rectified linear unit for activation function"
      ],
      "metadata": {
        "id": "rA8E1yXm9seR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 single image , 6 the filters we asked for,\n",
        "#26x26 is the image as we dont have padding and mnist data is all in the middle of the image so we are not losing any data but for other projects padding may be needed.\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbkR2E0t-hDf",
        "outputId": "5d8d1ce1-d056-479d-ced3-a606a256d3d7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pass thru pooling layer\n",
        "x=F.max_pool2d(x,2,2) # 2x2 kernel for pooling stride of 2"
      ],
      "metadata": {
        "id": "mIi05FPN_U4F"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#as we set kernel 2x2 the image is now 26/2 =13\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSiCK9Sl_d7C",
        "outputId": "87a89746-fc84-4616-fb44-cc9f9963c2a1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Do our second convolution layer\n",
        "x=F.relu(conv2(x))"
      ],
      "metadata": {
        "id": "BIYWm5Sq_tmN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape #again we didnt set padding so we lose 2 pixels around the images edges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCBYQ2fO_-Au",
        "outputId": "924ee66e-9a7d-470a-be8e-0e77715d09b2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pooling layer\n",
        "x=F.max_pool2d(x,2,2) #11/2 =5.5 but we have to round down, because we cant invent data to round up"
      ],
      "metadata": {
        "id": "uBMzOFCOAI_B"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABDjftw9MTIS",
        "outputId": "3da1187d-37a8-445d-b4dc-f295f7c14d8f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Class\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv1=nn.Conv2d(1,6,3,1)\n",
        "      self.conv2=nn.Conv2d(6,16,3,1)\n",
        "      #fully connected layer\n",
        "      self.fc1= nn.Linear(5*5*16,120)\n",
        "      self.fc2= nn.Linear(120,84)\n",
        "      self.fc3= nn.Linear(84,10)\n",
        "\n",
        "    #forward pass\n",
        "    def forward(self,x):\n",
        "      x=F.relu(self.conv1(x))\n",
        "      x=F.max_pool2d(x,2,2)\n",
        "      #second pass\n",
        "      x=F.relu(self.conv2(x))\n",
        "      x=F.max_pool2d(x,2,2)\n",
        "      #re-View to flatten out\n",
        "      x=x.view(-1,5*5*16) # negative one so we can vary the batch size\n",
        "      #Fully connected layers\n",
        "      x=F.relu(self.fc1(x))\n",
        "      x=F.relu(self.fc2(x))\n",
        "      x=self.fc3(x)\n",
        "      return F.log_softmax(x,dim=1)"
      ],
      "metadata": {
        "id": "BSDU4MLYAhTB"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance of model\n",
        "torch.manual_seed(41)\n",
        "model = ConvolutionalNetwork()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvlFLWitOrtH",
        "outputId": "8610529c-16a1-4bed-b72d-523240d9d45f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001) #smaller the lr the longer training will take.\n"
      ],
      "metadata": {
        "id": "s6x0di2BPzQO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hTUKgGgpQLtK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}