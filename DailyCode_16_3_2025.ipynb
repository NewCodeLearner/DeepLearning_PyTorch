{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZLCmh+4H3exqsX7QOQ+he",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NewCodeLearner/DeepLearning_PyTorch/blob/main/DailyCode_16_3_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Sf4pM9hkR-9j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.tensor(torch.randn(6,6))\n",
        "input = input.unsqueeze(0)\n",
        "input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AamA_iTJzOHd",
        "outputId": "bb2ec98c-49f2-4c8b-9b11-5da13db9f8a7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-145b7ed8c0ce>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input = torch.tensor(torch.randn(6,6))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input2 = input.squeeze(0)\n",
        "input2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGXiAJkH3pxa",
        "outputId": "7cde1e67-3f98-4373-990b-59edcb1e2551"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = torch.tensor([0.,1.,1.,0.,1.,0.])\n",
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrhTcWk9zvmg",
        "outputId": "8f275756-cfd8-4113-b36f-a9eb2b67cb7c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 1., 0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define model class\n",
        "\n",
        "class modelname(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.Net = nn.Sequential(\n",
        "            nn.Linear(6,10),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(10,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x = self.Net(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "WwHFr5bfz5kD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = modelname()"
      ],
      "metadata": {
        "id": "TNlLJniW1YKc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model(input)\n",
        "\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-5PzMGO1tNj",
        "outputId": "252ced23-b91b-434d-ed74-06445051f74a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4575],\n",
            "        [0.4181],\n",
            "        [0.5040],\n",
            "        [0.4345],\n",
            "        [0.4975],\n",
            "        [0.5063]], grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(logits.squeeze().shape)\n",
        "print(target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ey7fITw2Jo0",
        "outputId": "d4de3d9c-3f1f-409b-ee30-57d7c1dc24d9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6])\n",
            "torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "gHIUpGRn2RLo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = criterion(logits.squeeze(),target)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_IlnbDE2nn_",
        "outputId": "e6a468ba-19e1-4e1e-ab93-3ac6607f00ed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6905, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target2 = torch.tensor([[0.],[1.],[1.],[0.],[1.],[0.]])\n",
        "print(logits.shape)\n",
        "print(target2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzRTaLRJ29pw",
        "outputId": "4d3f74ff-82c2-472f-ac39-dede97caf9ff"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 1])\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = criterion(logits.squeeze(),target)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwqZDadN3Isn",
        "outputId": "72610b73-98da-4823-c1e2-fbd157de3778"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6905, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(logits.squeeze(0).shape)\n",
        "print(target2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STsSgl5FAwJm",
        "outputId": "405288eb-cdb4-4f21-9fa3-fbcf0ee4ded5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 1])\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "\n",
        "epochs=10\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=0.1)\n",
        "\n",
        "for i in range(epochs+1):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(input)\n",
        "    loss = criterion(logits.squeeze(0),target2)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print (f'Epoch: {i} Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ES7LqsP59kU",
        "outputId": "65310d25-5fa2-4a3e-b5d1-ad58c2d3e4fe"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 0.2350921481847763\n",
            "Epoch: 1 Loss: 0.21405546367168427\n",
            "Epoch: 2 Loss: 0.13907186686992645\n",
            "Epoch: 3 Loss: 0.10381504148244858\n",
            "Epoch: 4 Loss: 0.07883366197347641\n",
            "Epoch: 5 Loss: 0.05789707601070404\n",
            "Epoch: 6 Loss: 0.03835412487387657\n",
            "Epoch: 7 Loss: 0.02405918575823307\n",
            "Epoch: 8 Loss: 0.01405925303697586\n",
            "Epoch: 9 Loss: 0.008019265718758106\n",
            "Epoch: 10 Loss: 0.00454838527366519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(param for param in model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjM7TwwXBUtN",
        "outputId": "b84ad697-8943-425f-9c26-e722d6d24ec2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object <genexpr> at 0x7e9c5d717920>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edFxW2rmB5Nr",
        "outputId": "5fcff5ce-1e08-4cdb-d076-25689fa390ef"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-0.3096, -0.0031, -0.1512, -0.3410, -0.2397,  0.0384],\n",
            "        [-1.1178,  1.6172,  1.1656,  0.1887, -0.0405, -0.1954],\n",
            "        [-1.3462,  0.2270,  1.4784, -0.1079, -0.3410, -0.0376],\n",
            "        [-1.3712,  1.1161,  0.5361,  1.1425, -0.6535,  0.1731],\n",
            "        [-1.2164,  0.8678, -0.8803,  0.9904,  0.4788,  0.1882],\n",
            "        [-0.8776, -0.0582,  0.9348,  0.4484, -0.2248,  0.1299],\n",
            "        [-0.5524,  1.2666,  0.5328,  0.3320, -0.1775, -0.1870],\n",
            "        [-0.7829, -0.2376,  0.5157,  0.9657, -0.6710,  0.0713],\n",
            "        [ 1.1403, -1.5765, -1.1652,  1.6582, -0.4555, -1.3336],\n",
            "        [ 1.1752, -0.3628,  1.1044, -0.8035,  1.6993,  0.2583]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.4266, -0.5990, -0.3552, -0.1943, -0.4166, -0.5183, -0.2872, -0.6919,\n",
            "         1.2512,  0.5751], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.0726, -0.3534, -1.8007, -1.6067, -1.6386, -0.7430, -1.1186, -0.5945,\n",
            "          1.1204,  1.1300]], requires_grad=True), Parameter containing:\n",
            "tensor([1.3308], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get('https://raw.githubusercontent.com/ilya-pimenov/LLM-Study/refs/heads/main/the-verdict.txt')\n",
        "raw_text = response.text\n",
        "\n",
        "print(len(raw_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNS3ZL3hDTbi",
        "outputId": "aec5ebb0-9676-48b3-ab85-2a1491009458"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjyG2EMvEt-p",
        "outputId": "bc23ad15-5e3d-4fc6-8158-bac59abcfbca"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "print(tiktoken.list_encoding_names())\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RqVUjL6Eb_W",
        "outputId": "6ee2d924-62b7-43b3-ecbc-3b94894e55da"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gpt2', 'r50k_base', 'p50k_base', 'p50k_edit', 'cl100k_base', 'o200k_base']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWTP2wIkFo5A",
        "outputId": "6a9cee00-cf79-44e0-8b9c-8dab1d24e0c8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_text = tokenizer.encode(raw_text)\n",
        "tokenize_text[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WvzYKzSFCog",
        "outputId": "72688248-e72e-4d5d-ec7c-b61b1e1559d5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40,\n",
              " 367,\n",
              " 2885,\n",
              " 1464,\n",
              " 1807,\n",
              " 3619,\n",
              " 402,\n",
              " 271,\n",
              " 10899,\n",
              " 2138,\n",
              " 257,\n",
              " 7026,\n",
              " 15632,\n",
              " 438,\n",
              " 2016,\n",
              " 257,\n",
              " 922,\n",
              " 5891,\n",
              " 1576,\n",
              " 438]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tokenize_text[10:20]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6fAfh1cFNno",
        "outputId": "9bab06f1-4cee-4d7c-9fa4-be23f7c1dfc5"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " a cheap genius--though a good fellow enough--\n"
          ]
        }
      ]
    }
  ]
}